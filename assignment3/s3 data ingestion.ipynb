{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1dffe1a1-7e84-4fba-93bd-7b8db1ca76a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import io\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "446415b4-14d4-4d09-a803-8da5f537bee6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "s3 = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id='AKIAY7EVCTNDJB5HIRP5',\n",
    "    aws_secret_access_key='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'\n",
    ")\n",
    "\n",
    "bucket_name = 'ml-ops-kunal'\n",
    "s3_key = \"mlops-kunal/strengthFeatures.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "423b8b18-c29e-4a01-820e-e8baf5438c47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pdf = spark.table('workspace.default.strengthfeatures').toPandas()\n",
    "\n",
    "csv_buffer = io.StringIO()\n",
    "\n",
    "# Write pandas df to this buffer\n",
    "pdf.to_csv(csv_buffer, index=False)\n",
    "\n",
    "# Upload the CSV from the buffer\n",
    "s3.put_object(Bucket=bucket_name, Key=s3_key, Body=csv_buffer.getvalue())\n",
    "\n",
    "print(f\"Successfully uploaded data to s3://{bucket_name}/{s3_key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c374fea9-1307-4de8-8ce8-22e9484ad97e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pdf = spark.table('workspace.default.behaviorfeaturesenhanced').toPandas()\n",
    "\n",
    "csv_buffer = io.StringIO()\n",
    "\n",
    "# Write pandas df to this buffer\n",
    "pdf.to_csv(csv_buffer, index=False)\n",
    "\n",
    "# Upload the CSV from the buffer\n",
    "s3_key = \"mlops-kunal/behaviorFeaturesEnhanced.csv\"\n",
    "s3.put_object(Bucket=bucket_name, Key=s3_key, Body=csv_buffer.getvalue())\n",
    "\n",
    "print(f\"Successfully uploaded data to s3://{bucket_name}/{s3_key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f099fe25-2654-414a-a3eb-ac7e4f27ed52",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pdf = spark.table('workspace.default.behaviorfeaturesmodel').toPandas()\n",
    "\n",
    "csv_buffer = io.StringIO()\n",
    "\n",
    "# Write pandas df to this buffer\n",
    "pdf.to_csv(csv_buffer, index=False)\n",
    "\n",
    "# Upload the CSV from the buffer\n",
    "s3_key = \"mlops-kunal/behaviorFeaturesModel.csv\"\n",
    "s3.put_object(Bucket=bucket_name, Key=s3_key, Body=csv_buffer.getvalue())\n",
    "\n",
    "print(f\"Successfully uploaded data to s3://{bucket_name}/{s3_key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8ef3b45-bc07-4170-b559-ead1879f3309",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "raw = spark.table('workspace.default.athletes_raw')\n",
    "# Create total_lift column\n",
    "raw = raw.withColumn('total_lift', F.col('snatch') + F.col('deadlift') + F.col('backsq') + F.col('candj'))\n",
    "cols_to_drop = (\"snatch\",\"deadlift\",\"backsq\",\"candj\",)\n",
    "raw = raw.drop(*cols_to_drop)\n",
    "raw_pd = raw.toPandas()\n",
    "raw_pd = raw_pd.dropna(subset=['total_lift'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d8d2686-b7b4-4a3f-81d5-c68741bf646e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "csv_buffer = io.StringIO()\n",
    "\n",
    "# Write pandas df to this buffer\n",
    "raw_pd.to_csv(csv_buffer, index=False)\n",
    "\n",
    "# Upload the CSV from the buffer\n",
    "s3_key = \"mlops-kunal/raw_athletes.csv\"\n",
    "s3.put_object(Bucket=bucket_name, Key=s3_key, Body=csv_buffer.getvalue())\n",
    "\n",
    "print(f\"Successfully uploaded data to s3://{bucket_name}/{s3_key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76005959-b8ff-4a8c-b5e3-1928f402b652",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pdf = spark.table('workspace.default.total_lift_labels').toPandas()\n",
    "\n",
    "csv_buffer = io.StringIO()\n",
    "\n",
    "# Write pandas df to this buffer\n",
    "pdf.to_csv(csv_buffer, index=False)\n",
    "\n",
    "# Upload the CSV from the buffer\n",
    "s3_key = \"assignment3/total_lift_labels.csv\"\n",
    "s3.put_object(Bucket=bucket_name, Key=s3_key, Body=csv_buffer.getvalue())\n",
    "\n",
    "print(f\"Successfully uploaded data to s3://{bucket_name}/{s3_key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b166e72-9398-400c-a948-3b7d427e03d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pdf = spark.table('workspace.default.total_lift_labels').toPandas()\n",
    "pdf.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0eeaf6d-4e55-44b2-87b8-3cbfd66744c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "len(pdf)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "s3 data ingestion",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
