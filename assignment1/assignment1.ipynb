{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9031d78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lakefs-client\n",
      "  Using cached lakefs_client-1.44.0-py3-none-any.whl.metadata (41 kB)\n",
      "Requirement already satisfied: urllib3>=1.25.3 in /Users/kunal/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from lakefs-client) (1.26.12)\n",
      "Requirement already satisfied: python-dateutil in /Users/kunal/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from lakefs-client) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/kunal/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from python-dateutil->lakefs-client) (1.16.0)\n",
      "Using cached lakefs_client-1.44.0-py3-none-any.whl (378 kB)\n",
      "Installing collected packages: lakefs-client\n",
      "Successfully installed lakefs-client-1.44.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install lakefs-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45edba51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lakefs_client\n",
    "# from lakefs_client import Configuration\n",
    "# from lakefs_client.client import repositories_api, branches_api, objects_api\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04392bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your actual values\n",
    "lakefs_endpoint = \"http://localhost:8000\"\n",
    "access_key = \"AKIA...\"\n",
    "secret_key = \"abc123...\"\n",
    "\n",
    "configuration = Configuration()\n",
    "configuration.username = access_key\n",
    "configuration.password = secret_key\n",
    "configuration.host = lakefs_endpoint\n",
    "\n",
    "client = LakeFSClient(configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c676606f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(raw_data):\n",
    "    clean_data = raw_data.copy()\n",
    "    # Remove not relevant columns\n",
    "    clean_data = clean_data.dropna(subset=['region','age','weight','height','howlong','gender','eat', \\\n",
    "                               'train','background','experience','schedule','howlong', \\\n",
    "                               'deadlift','candj','snatch','backsq','experience',\\\n",
    "                               'background','schedule','howlong'])\n",
    "    clean_data = clean_data.drop(columns=['affiliate','team','name','athlete_id','fran','helen','grace',\\\n",
    "                              'filthy50','fgonebad','run400','run5k','pullups','train'])\n",
    "\n",
    "    # Remove Outliers\n",
    "\n",
    "    clean_data = clean_data[clean_data['weight'] < 1500]\n",
    "    clean_data = clean_data[clean_data['gender'] != '--']\n",
    "    clean_data = clean_data[clean_data['age'] >= 18]\n",
    "    clean_data = clean_data[(clean_data['height'] < 96) & (clean_data['height'] > 48)]\n",
    "\n",
    "    clean_data = clean_data[(clean_data['deadlift'] > 0) & (clean_data['deadlift'] <= 1105)|((clean_data['gender'] == 'Female') \\\n",
    "                 & (clean_data['deadlift'] <= 636))]\n",
    "    clean_data = clean_data[(clean_data['candj'] > 0) & (clean_data['candj'] <= 395)]\n",
    "    clean_data = clean_data[(clean_data['snatch'] > 0) & (clean_data['snatch'] <= 496)]\n",
    "    clean_data = clean_data[(clean_data['backsq'] > 0) & (clean_data['backsq'] <= 1069)]\n",
    "\n",
    "    # Clean Survey Data\n",
    "\n",
    "    decline_dict = {'Decline to answer|': np.nan}\n",
    "    clean_data = clean_data.replace(decline_dict)\n",
    "    clean_data = clean_data.dropna(subset=['background','experience','schedule','howlong','eat'])\n",
    "    return clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a52c284f",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_data = pd.read_csv('athletes.csv')\n",
    "clean_data = clean_data(orig_data)\n",
    "clean_data.to_csv('athletes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d833c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['athlete_id', 'name', 'region', 'team', 'affiliate', 'gender', 'age',\n",
       "       'height', 'weight', 'fran', 'helen', 'grace', 'filthy50', 'fgonebad',\n",
       "       'run400', 'run5k', 'candj', 'snatch', 'deadlift', 'backsq', 'pullups',\n",
       "       'eat', 'train', 'background', 'experience', 'schedule', 'howlong'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_data.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
